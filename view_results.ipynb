{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import os\n",
    "from collections import Counter, OrderedDict\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "import numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Load results of all methods tested\n",
    "'''\n",
    "\n",
    "base_folders = './experiments/domain2/'\n",
    "\n",
    "raw_records = {}\n",
    "seed_folders = ['1111/'] # select the seed that you want to check\n",
    "\n",
    "print('Methods to check')\n",
    "for seed_folder in seed_folders:\n",
    "    \n",
    "    raw_records[seed_folder] = {}\n",
    "    for exp_folder in sorted(os.listdir(base_folders + seed_folder)):\n",
    "    \n",
    "        if exp_folder != '.DS_Store':\n",
    "            print (exp_folder)\n",
    "            path = base_folders + seed_folder + exp_folder + '/lm/model/' # replace to '/cvae/modeel/' if you test cvae\n",
    "            raw_records[seed_folder][exp_folder] = []\n",
    "            for file in sorted(os.listdir(path)):\n",
    "\n",
    "                if file != '.DS_Store':\n",
    "                    ckp = torch.load(path+file,map_location='cpu')['perf']\n",
    "                    raw_records[seed_folder][exp_folder].append(ckp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabulate_results_all(records):\n",
    "    '''\n",
    "    tabulate results for omega_all, omega_first\n",
    "    '''\n",
    "    \n",
    "    formated_results = []\n",
    "    all_results = {}\n",
    "    for seed, results in records.items():\n",
    "        for method, perf in results.items():\n",
    "\n",
    "            result = []\n",
    "            sequence = [0,5,2,1,3,4]\n",
    "            for run in perf:\n",
    "                # all\n",
    "                result.append(run['cul_se'])\n",
    "                result.append(run['cul_bleu'][3])\n",
    "                # base (the first domain: 0) replace to the first of {task_seq} in c{onfig} if you use other order\n",
    "                first = 0\n",
    "                result.append(run['se'][first])\n",
    "                result.append(run['bleu'][first][3])              \n",
    "\n",
    "            result = np.asarray(result).reshape(6,4).T.mean(1)\n",
    "            \n",
    "            if method in all_results.keys():\n",
    "                all_results[method] += [result]\n",
    "            else:\n",
    "                all_results[method] = [result]\n",
    "    \n",
    "    for method, result in all_results.items():\n",
    "        result = np.array(result)\n",
    "        mean_result = list(result.mean(axis=0))\n",
    "    \n",
    "        formated_results.append( [method] + mean_result )\n",
    "\n",
    "    headers = ['Methods', 'ALL SER', 'ALL BLEU', 'First SER','First BLEU']\n",
    "    \n",
    "    return formated_results, headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, headers = tabulate_results_all(raw_records)\n",
    "dataframe = pd.DataFrame(results, columns=headers)\n",
    "display(HTML(dataframe.to_html()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
